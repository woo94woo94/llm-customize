import { loadConfig } from "../config/index.js";
import { ChatCustomGpt } from "../clients/langchain/ChatCustomGpt.js";
import { StateGraph, MessagesAnnotation } from "@langchain/langgraph";
import { HumanMessage } from "@langchain/core/messages";
import { ToolNode } from "@langchain/langgraph/prebuilt";
import { tool } from "@langchain/core/tools";
import { z } from "zod";

// ê°„ë‹¨í•œ ë‚ ì”¨ ì¡°íšŒ tool ì •ì˜
const weatherTool = tool(
  async ({ location }) => {
    // ì‹¤ì œë¡œëŠ” ë‚ ì”¨ APIë¥¼ í˜¸ì¶œí•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” mock ë°ì´í„° ë°˜í™˜
    const mockWeather: Record<string, string> = {
      ì„œìš¸: "ë§‘ìŒ, 15Â°C",
      ë¶€ì‚°: "íë¦¼, 18Â°C",
      ì œì£¼: "ë¹„, 20Â°C",
    };
    return mockWeather[location] || "ì •ë³´ ì—†ìŒ";
  },
  {
    name: "get_weather",
    description: "íŠ¹ì • ì§€ì—­ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤",
    schema: z.object({
      location: z.string().describe("ë‚ ì”¨ë¥¼ ì¡°íšŒí•  ì§€ì—­ëª…"),
    }),
  }
);

// ê³„ì‚°ê¸° tool ì •ì˜
const calculatorTool = tool(
  async ({ expression }) => {
    try {
      // ê°„ë‹¨í•œ ìˆ˜ì‹ ê³„ì‚° (ìœ„í—˜: eval ì‚¬ìš©, ì‹¤ì œë¡œëŠ” ì•ˆì „í•œ íŒŒì„œ ì‚¬ìš© ê¶Œì¥)
      const result = eval(expression);
      return `${expression} = ${result}`;
    } catch (error) {
      return `ê³„ì‚° ì˜¤ë¥˜: ${error}`;
    }
  },
  {
    name: "calculator",
    description: "ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤",
    schema: z.object({
      expression: z.string().describe("ê³„ì‚°í•  ìˆ˜ì‹ (ì˜ˆ: 2 + 2)"),
    }),
  }
);

async function main() {
  const config = loadConfig();

  console.log("=== LangGraph + Tools í…ŒìŠ¤íŠ¸ ===\n");

  // tools ë°°ì—´
  const tools = [weatherTool, calculatorTool];

  // ChatCustomGpt ëª¨ë¸ ìƒì„± ë° tools ë°”ì¸ë”©
  const model = new ChatCustomGpt({
    ...config,
    temperature: 0.7,
  });

  const modelWithTools = model.bindTools(tools);

  // ToolNode ìƒì„±
  const toolNode = new ToolNode(tools);

  // ì¡°ê±´ë¶€ ì—£ì§€: tool í˜¸ì¶œì´ ìˆìœ¼ë©´ tools ë…¸ë“œë¡œ, ì—†ìœ¼ë©´ ì¢…ë£Œ
  const shouldContinue = (state: typeof MessagesAnnotation.State) => {
    const { messages } = state;
    const lastMessage = messages[messages.length - 1];
    if (
      lastMessage &&
      "tool_calls" in lastMessage &&
      Array.isArray(lastMessage.tool_calls) &&
      lastMessage.tool_calls?.length
    ) {
      return "tools";
    }
    return "__end__";
  };

  // ëª¨ë¸ í˜¸ì¶œ ë…¸ë“œ
  const callModel = async (state: typeof MessagesAnnotation.State) => {
    const { messages } = state;
    const response = await modelWithTools.invoke(messages);
    return { messages: [response] };
  };

  // StateGraph ì •ì˜
  const workflow = new StateGraph(MessagesAnnotation)
    .addNode("agent", callModel)
    .addNode("tools", toolNode)
    .addEdge("__start__", "agent")
    .addConditionalEdges("agent", shouldContinue, {
      tools: "tools",
      __end__: "__end__",
    })
    .addEdge("tools", "agent");

  const app = workflow.compile();

  console.log("ğŸ“ í…ŒìŠ¤íŠ¸: Toolì„ ì‚¬ìš©í•˜ëŠ” Agent\n");
  console.log("ì‚¬ìš© ê°€ëŠ¥í•œ tools:");
  tools.forEach((tool) => {
    console.log(`- ${tool.name}: ${tool.description}`);
  });
  console.log("\n");

  try {
    const stream = await app.stream(
      {
        messages: [
          new HumanMessage(
            "get_weather íˆ´ì„ ì‚¬ìš©í•´ì„œ ì„œìš¸ ë‚ ì”¨ë¥¼ ì•Œë ¤ì£¼ê³ , calculator íˆ´ì„ ì‚¬ìš©í•´ì„œ 25*4ë¥¼ ê³„ì‚°í•´ì¤˜"
          ),
        ],
      },
      { streamMode: "values" }
    );

    for await (const chunk of stream) {
      const lastMessage = chunk.messages[chunk.messages.length - 1];
      if (!lastMessage) continue;

      const type = lastMessage._getType();
      const content = lastMessage.content;
      const toolCalls = (lastMessage as any).tool_calls;

      console.log({
        type,
        content: typeof content === "string" ? content : JSON.stringify(content),
        toolCalls: toolCalls || "ì—†ìŒ",
      });
      console.log("-----\n");
    }
  } catch (error) {
    console.error("ì—ëŸ¬ ë°œìƒ:", error);
  }
}

main().catch(console.error);
